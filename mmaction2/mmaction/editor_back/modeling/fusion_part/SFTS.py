import torch
import torch.nn as nn
import math
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
from einops import rearrange

from mmengine.visualization import TensorboardVisBackend
from mmaction.models.common.transformer import visualize_attention
from mmaction.models.common.transformer import visualize_attention_heatmap
writer = TensorboardVisBackend(save_dir='/home/qingyuhan/sota_code/mmaction2/test_vis_3')
# Cut & paste from PyTorch official master until it's in a few official releases - RW
# Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf
caculate_pic=0
caculate_pic_batch=1
from mmaction.editor_back.modeling.backbones.vit_pytorch import BlockMask,Block,BlockFuse
def _no_grad_trunc_normal_(tensor, mean, std, a, b):
    # Cut & paste from PyTorch official master until it's in a few official releases - RW
    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf
    def norm_cdf(x):
        # Computes standard normal cumulative distribution function
        return (1. + math.erf(x / math.sqrt(2.))) / 2.

    if (mean < a - 2 * std) or (mean > b + 2 * std):
        print("mean is more than 2 std from [a, b] in nn.init.trunc_normal_. "
              "The distribution of values may be incorrect.", )

    with torch.no_grad():
        # Values are generated by using a truncated uniform distribution and
        # then using the inverse CDF for the normal distribution.
        # Get upper and lower cdf values
        l = norm_cdf((a - mean) / std)
        u = norm_cdf((b - mean) / std)

        # Uniformly fill tensor with values from [l, u], then translate to
        # [2l-1, 2u-1].
        tensor.uniform_(2 * l - 1, 2 * u - 1)

        # Use inverse cdf transform for normal distribution to get truncated
        # standard normal
        tensor.erfinv_()

        # Transform to proper mean, std
        tensor.mul_(std * math.sqrt(2.))
        tensor.add_(mean)

        # Clamp to ensure it's in the proper range
        tensor.clamp_(min=a, max=b)
        return tensor

def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):
    # type: (Tensor, float, float, float, float) -> Tensor
    r"""Fills the input Tensor with values drawn from a truncated
    normal distribution. The values are effectively drawn from the
    normal distribution :math:`\mathcal{N}(\text{mean}, \text{std}^2)`
    with values outside :math:`[a, b]` redrawn until they are within
    the bounds. The method used for generating the random values works
    best when :math:`a \leq \text{mean} \leq b`.
    Args:
        tensor: an n-dimensional `model.Tensor`
        mean: the mean of the normal distribution
        std: the standard deviation of the normal distribution
        a: the minimum cutoff value
        b: the maximum cutoff value
    Examples:
        >>> w = model.empty(3, 5)
        >>> nn.init.trunc_normal_(w)
    """
    return _no_grad_trunc_normal_(tensor, mean, std, a, b)

# Here, you can use the below function to get the Selection results in SUPP

def display_image(image_path, mode=1):
    pre_fix = '/13994058190/WYH/EDITOR/data/RGBNT201/train_171/'
    if mode == 1:
        pre_fix = pre_fix + 'RGB/'
    elif mode == 2:
        pre_fix = pre_fix + 'NI/'
    elif mode == 3:
        pre_fix = pre_fix + 'TI/'
    image = Image.open(pre_fix + image_path)
    resized_image = image.resize((128, 256))  # Resize to 256x128
    plt.imshow(resized_image)
    plt.axis('off')
    plt.show()





# class Part_Attention(nn.Module):
#     def __init__(self):
#         super(Part_Attention, self).__init__()
#
#     def forward(self, x,mask):
#         last_map = x[:, 0, 1:][mask[:12]].unsqueeze(2)
#
#         # last_map=rearrange(last_map,'h (t n)->t h n',t=8,n=196)
#         # N =last_map.shape[1]  #num_tokens
#         # B =last_map.shape[0]
#         # selected_tokens_mask = torch.zeros((B, N), dtype=torch.bool).cuda()
#         # for i in range(last_map.shape[0]):
#         #     if mask[i]==2:
#         #         _, topk_indices = torch.topk(last_map[i,:], 80, dim=0)
#         #     elif mask[i]==1:
#         #         _, topk_indices = torch.topk(last_map[i, :], 40, dim=0)
#         #     else:
#         #         _, topk_indices = torch.topk(last_map[i, :], 10, dim=0)
#         #
#         #     topk_indices = torch.sort(topk_indices, dim=0).values
#         #     selected_tokens_mask[i].scatter_(0, topk_indices, 1)
#         #
#         #
#         # return _, selected_tokens_mask



import torch.nn.functional as F
def find_max_window_sum(x,mask):
    last_map=rearrange(x[:,0,1:],'b (h w) -> b h w ',h=14,w=14)

    # 创建一个6x8的卷积核，所有元素都是1
    # window1 = torch.ones(1, 1, 10,6).cuda()  # 6x8的窗口，添加通道维度
    # window1_size=(10,6)
    # window2 = torch.ones(1, 1, 9,7).cuda()  # 6x8的窗口，添加通道维度
    # window2_size = (9,7)
    window = torch.ones(1, 1, 10, 7).cuda()  # 6x8的窗口，添加通道维度
    window_size = (10,7)
    N = last_map.shape[1]  # num_tokens
    B = last_map.shape[0]
    selected_tokens_mask = torch.zeros((B, 196), dtype=torch.bool).cuda()

    for i in range(last_map.shape[0]):
        # if mask[i] == 2:
        #     result = F.conv2d(last_map[i,:,:].unsqueeze(0), window1, stride=1)
        #
        #     # 找到最大得分及其位置
        #     max_score = torch.max(result)
        #     max_position = torch.argmax(result).tolist()
        #
        #     # 确定标记的位置
        #     # 在14x14矩阵中计算窗口区域
        #     top_left_row = max_position // 9
        #     top_left_col = max_position % 9
        #     bottom_right_row = top_left_row + window1_size[0]
        #     bottom_right_col = top_left_col + window1_size[1]
        if mask[i] == 1:
            result = F.conv2d(last_map[i,:,:].unsqueeze(0), window, stride=1)

            # 找到最大得分及其位置
            max_score = torch.max(result)
            max_position = torch.argmax(result).tolist()

            # 确定标记的位置
            # 在14x14矩阵中计算窗口区域
            top_left_row = max_position // (15-window_size[1])
            top_left_col = max_position % (15-window_size[1])
            bottom_right_row = top_left_row + window_size[0]
            bottom_right_col = top_left_col + window_size[1]
        # # else:
        #     # result = F.conv2d(last_map[i,:,:].unsqueeze(0), window, stride=1)

        if mask[i]==1 or mask[i]==2:
            # 标记对应区域
            for row in range(top_left_row, bottom_right_row):
                for col in range(top_left_col, bottom_right_col):
                    index = row * 14 + col
                    # selected_tokens_mask[i].scatter_(0, index%196, 1)
                    selected_tokens_mask[i][index%196]=1


    return selected_tokens_mask






class Part_Attention(nn.Module):
    def __init__(self):
        super(Part_Attention, self).__init__()

    def forward(self, x,mask):
        last_map = x[:, 0, 1:].squeeze(0)

        # last_map=rearrange(last_map,'h (t n)->t h n',t=8,n=196)
        N =last_map.shape[1]  #num_tokens
        B =last_map.shape[0]
        selected_tokens_mask = torch.zeros((B, N), dtype=torch.bool).cuda()
        #120 70
        #90 50
        #60 30
        for i in range(last_map.shape[0]):
            if mask[i]==2:
                _, topk_indices = torch.topk(last_map[i,:], 120, dim=0)
            elif mask[i]==1:
                _, topk_indices = torch.topk(last_map[i, :], 70, dim=0)
            else:
                _, topk_indices = torch.topk(last_map[i, :], 1, dim=0)

            topk_indices = torch.sort(topk_indices, dim=0).values
            selected_tokens_mask[i].scatter_(0, topk_indices, 1)


        return _, selected_tokens_mask




class SFTS(nn.Module):
    def __init__(self):
        super(SFTS, self).__init__()
        self.part_select = Part_Attention()

    def _init_weights(self, m):
        if isinstance(m, nn.Linear):
            trunc_normal_(m.weight, std=.02)
            if isinstance(m, nn.Linear) and m.bias is not None:
                nn.init.constant_(m.bias, 0)
        elif isinstance(m, nn.LayerNorm):
            nn.init.constant_(m.bias, 0)
            nn.init.constant_(m.weight, 1.0)

    def forward(self, Vis_feat, Vis_attn, mask_fre=None,identity_x=None):

        _, Vis_index= self.part_select(Vis_attn,mask_fre)


        index=Vis_index.reshape(1,-1,1)
        # global caculate_pic, caculate_pic_batch
        # caculate_pic += 1
        # # # # # # 记录可见光模态图像和注意力映射
        # if not self.training:
        #     global caculate_pic,caculate_pic_batch
        #     caculate_pic += 1
        #     # # print(caculate_pic)
        # #     # if caculate_pic == 240: #529#3960
        # #     #     caculate_pic=0
        # #     #     caculate_pic_batch+=1
        # #     # elif caculate_pic_batch>=10:
        #     visualize_attention(writer, identity_x[0], index.squeeze(0).squeeze(1)[:1568],mask_fre[:8],'Val_{}_the_{}_Visible_Attention_Map'.format(caculate_pic_batch,(caculate_pic)))
        #     visualize_attention(writer, identity_x[1], index.squeeze(0).squeeze(1)[1568:],mask_fre[8:],'Val_{}_the_{}_Infrared_Attention_Map'.format(caculate_pic_batch, (caculate_pic)))

        #to return mask_token with cls
        Vis_parts = Vis_feat[:, 1:, :] * index
        Vis_feats = torch.cat([Vis_feat[:, 0].unsqueeze(1), Vis_parts], dim=1)
        return Vis_feats, index


import torch
import torchvision.utils as vutils
from torch.utils.tensorboard import SummaryWriter
import numpy as np

def visualize_attention_with_boxes(writer, images, patch_indices, tag, nrow=8):
    """
    Visualizes images with overlaid attention boxes in TensorBoard.

    :param writer: TensorBoard SummaryWriter object.
    :param images: Tensor of shape (num_images, 3, 224, 224), the input images.
    :param patch_indices: Tensor or list of patch indices (num_images, num_patches).
    :param tag: String tag for TensorBoard.
    :param nrow: Number of images per row in the grid.
    """
    num_images, num_channels, height, width = images.shape

    # Iterate through each image and its corresponding patch indices
    for j in range(num_images):
        image = images[j].cpu().numpy().transpose(1, 2, 0)  # Convert to HWC format for plotting
        image = np.ascontiguousarray(image)

        # Convert image to 0-1 range
        image_min = np.min(image)
        image_max = np.max(image)
        image = (image - image_min) / (image_max - image_min)

        patch_idx = patch_indices[j]  # Get the patch indices for this image

        # Initialize a blank mask with the same dimensions as the image
        attention_overlay = np.zeros_like(image)

        # Iterate through each patch index
        for idx in patch_idx:
            # Compute the top-left corner (x, y) and the width and height (w, h)
            x = (idx % 6) * 14
            y = (idx // 6) * 14
            w, h = 14 * 6, 14 * 6

            # Draw the attention box (set the region to max value to create a highlight)
            attention_overlay[y:y+h, x:x+w, :] = 1.0  # Overlay white box on the region of interest

        # Combine original image and attention overlay
        combined_image = np.clip(image + attention_overlay * 0.5, 0, 1)

        # Convert back to CHW format for TensorBoard
        combined_image = torch.tensor(combined_image.transpose(2, 0, 1))

        # Create an image grid for TensorBoard visualization
        img_grid = vutils.make_grid(combined_image.unsqueeze(0), nrow=nrow, normalize=False, scale_each=False)
        writer.add_image(f'{tag}/attention_overlay_{j}', img_grid)

# Usage example
# writer = SummaryWriter('runs/experiment_name')
# images = torch.randn(16, 3, 224, 224)  # Replace with actual images tensor
# patch_indices = torch.randint(0, 36, (16, 5))  # Replace with actual patch indices
# visualize_attention_with_boxes(writer, images, patch_indices, tag='Attention', nrow=4)
# writer.close()


from scipy.ndimage import label
# 这个函数是为了避免某些孤立的token对整体判断造成干扰，
# minsize是满足的最小连通图的条件
def remove_isolated_pixels(mask,min_size):
    # 确保输入掩码是一个numpy数组
    mask = np.array(mask.cpu(), dtype=np.int_)
    # 创建一个新的掩码，用于存储结果
    new_mask = np.zeros_like(mask)
    for i in range(mask.shape[0]):
        # 使用scipy.ndimage.label找到掩码中的所有连通组件
        labeled_mask, num_labels = label(mask[i])



        for label_num in range(1, num_labels + 1):  # 标签从1开始，因为0是背景
            component_size = np.sum(labeled_mask == label_num)
            if component_size >=min_size:
                new_mask[i][labeled_mask == label_num] = 1

    return (torch.from_numpy(new_mask)).view(8,196).cuda()



